{
  "hash": "e66d32cb63b034dd37916e14cfdcb2ee",
  "result": {
    "markdown": "---\ntitle: \"A Simple Digit Classifier\"\nauthor: \"David De Sa\"\ndate: \"2023-03-14\"\ncategories: [python, pyTorch, NeuralNetworks]\nimage: \"NN101_thumbnail.png\"\nformat:\n  html:\n    code-fold: true\n    toc: true\n    code-tools: true\ndraft: true\n---\n\n## TL;DR\nThe best way to learn is to teach, so in this post I try to teach the reader how my first neural network implementation works! Part 2 of 2. I built this in following along with the awesome lessons over at [fast.ai](course.fast.ai). Many thanks to that team.\n\n# Overview\nWe're going to jump in where we left off in Part 1: We'll just reimport our data, and get into it.\n\n### What?\nWe're going to create a neural network that, given a picture of a numeric digit, identifies the number.\n\n### Why?\nDoes this really need explaining? Because the technology is amazing in both practical and philosophical ways.\n\n### Who?\n[Who am I](https://davidd003.github.io/Coding_Blog/about.html)!? Who are you?!\n\n### How?\nUsing [PyTorch](https://pytorch.org/)^[If it ain't 'py', it ain't python, right?], an opensource toolkit for building neural networks. Truly an elevator ride up onto the shoulders of giants.\n\n# Code Review\nWe'll first just re-import our data, and then get into building the groundwork for our neural network\n\nLet's get into it!\n\n::: {.callout-note collapse=\"true\"}\nThe required dependencies!:`scikit-learn`, `fastbook`, `matplotlib`\n:::\n\n::: {.cell execution_count=1}\n``` {.python .cell-code code-line-numbers=\"true\"}\n# Install dependency\nfrom fastbook import *\nfrom fastai.vision.all import *\nfrom sklearn.datasets import load_digits\nimport fastbook\n\nfastbook.setup_book()\n\n\nmatplotlib.rc(\"image\", cmap=\"Greys\")\n```\n:::\n\n\n## Data Acquisition\nA quick flashback to Part 1 of my Building A Digit Classifier blog!:\n\n::: {.callout-tip collapse=\"true\"}\n## Understand Your Input!\n\nPre-processing data before even touching any neural net methods can improve your final performance. Note the data set information offered at the [source page](https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits): \n\n> We used preprocessing programs made available by NIST to extract normalized bitmaps of handwritten digits from a preprinted form. From a total of 43 people, 30 contributed to the training set and different 13 to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of 4x4 and the number of on pixels are counted in each block. This generates an input matrix of 8x8 where each element is an integer in the range 0..16. This reduces dimensionality and gives invariance to small distortions.\n:::\n\n::: {.cell execution_count=2}\n``` {.python .cell-code code-line-numbers=\"true\"}\nmnist = load_digits()\nstacked = []\n# This loop because stacked=[[]]*10 makes 1 list in list, with 10 copies of pointers... need separate objects\nfor i in range(10):\n    stacked.append([])\n# Assign all images to the right collection in the 'stacked' list, indexed by target\nfor i in range(len(mnist[\"target\"])):\n    stacked[mnist[\"target\"][i]].append(mnist[\"images\"][i])\n```\n:::\n\n\n### Segmentation\nThe next step is to define which data will be our training, and our validation set. It was important to bucket out our data first so by randomly sampling our data we didn't generate a validation set with a large imbalance in the number of classes to be tested in it. \n\nFirst we convert to a tensor, then segment training from validation data. Arbitrarily taking 20 examples from each digit, so, 11.5% of the total data set towards validation.\n\nWe'll print out the size of these collections and take a peek at a sample to make sure we indexed right.\n\n:::{#fig-checkSamp}\n\n::: {.cell execution_count=3}\n``` {.python .cell-code code-line-numbers=\"true\"}\n# To make dataset a tensor, make it same number of dimensions\nstacked = tensor([x[:174] for x in stacked])\n# Segmentation: Pull 20 of each digit out of training set\ntest = [dig[-20:] for dig in stacked]\ntrain = [dig[:-20] for dig in stacked]\n# Confirm counts of samples\n[len(test[i]) for i in range(10)], [len(train[i]) for i in range(10)]\nshow_image(stacked[3][0])  # Check sample\n```\n\n::: {.cell-output .cell-output-display execution_count=79}\n```\n<Axes: >\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-4-output-2.png){width=93 height=93}\n:::\n:::\n\n\nIs it a 3?\n:::\nNice.\n\nIt's important to keep track of what's what.\n\n::: {.cell execution_count=4}\n``` {.python .cell-code code-fold=\"show\" code-line-numbers=\"true\"}\ntype(train), type(train[0]), type(train[0][0]), [\n    type(test), type(test[0]), type(test[0][0])]\n```\n\n::: {.cell-output .cell-output-display execution_count=80}\n```\n(list, torch.Tensor, torch.Tensor, [list, torch.Tensor, torch.Tensor])\n```\n:::\n:::\n\n\nOk so our top level containers for training/testing data are basic python lists. Within those, we have 10 collections, one for each integer. Those are Tensors. And then, each image (a collection of pixels unto itself) within those tensors, are also Tensor type objects.\n\nInstead of a basic Python list, we will need the top level containers as tensors to leverage the pyTorch functionality built into them. luckily it's an easy conversion:\n\n::: {.cell execution_count=5}\n``` {.python .cell-code code-line-numbers=\"true\"}\n# Converts PyList of tensors to tensor of tesnors (join in new dimensions, retain target indexing)\ntrain = torch.stack(train)\ntest = torch.stack(test)\ntrain.shape, test.shape\n```\n\n::: {.cell-output .cell-output-display execution_count=81}\n```\n(torch.Size([10, 154, 8, 8]), torch.Size([10, 20, 8, 8]))\n```\n:::\n:::\n\n\nNow here is a critical piece, working with multidimensional arrays and keeping in mind what we understand these to be. Our test and training tensors have the same dimensionality but not the same size. \n\n### Setup DataLoaders\nFirst get data into the requisite shape for the processes that will follow. \n\n::: {.cell execution_count=6}\n``` {.python .cell-code code-line-numbers=\"true\"}\n# Build training/valid sets for passing to DataLoader\ntrain_x = torch.cat([x for x in train]).view(-1, 8*8)\ntest_x = torch.cat([x for x in test]).view(-1, 8*8)\ntrain_y, test_y = [], []\nfor n in range(10):\n    train_y.extend([n]*154)\n    test_y.extend([n]*20)\ntrain_y = tensor(train_y).unsqueeze(-1)\ntest_y = tensor(test_y).unsqueeze(-1)\ntrain_x.shape, test_x.shape, train_y.shape, test_y.shape\n```\n\n::: {.cell-output .cell-output-display execution_count=82}\n```\n(torch.Size([1540, 64]),\n torch.Size([200, 64]),\n torch.Size([1540, 1]),\n torch.Size([200, 1]))\n```\n:::\n:::\n\n\nNote the unsqueezing such that the `_y` tensors have a singleton dimension. Might seem strange on first blush but makes sense when considering that our 'target' just happens to be individual integers. But in other use cases, the target could be something more complex, requiring a larger data structure. In which case that dimension could be larger than a singleton.\n\nNow we can prime our DataLoaders. DataLoaders are a super handy object from the Pytorch library that will make life easier by holding our data for us, and serving it up in randomized batches.\n\n::: {.cell execution_count=7}\n``` {.python .cell-code code-line-numbers=\"true\"}\n# Zip each input data item to its target output\ndset = list(zip(train_x, train_y))\nvalid_dset = list(zip(test_x, test_y))\n# Define DataLoader objects to pass to learner\ndl = DataLoader(dset, batch_size=25, shuffle=true)\nvalid_dl = DataLoader(valid_dset, batch_size=5, shuffle=true)\n\ndls = DataLoaders(dl, valid_dl)\n```\n:::\n\n\n## Laying The NN Foundations\nEvery NN needs weights and biases. We're going to want to initialize lots of them, and in differently shaped structures, so first we define a function to help us do that:\n\n::: {.cell execution_count=8}\n``` {.python .cell-code code-line-numbers=\"true\"}\ndef init_params(size, std=.1): return (torch.randn(size)*std).requires_grad_()\n\n```\n:::\n\n\n::: {.callout-note collapse=\"true\"}\n## Requiring Grad!\nNote that any memory structures created with that function will also store their gradient in memory as computation is performed on them. This will be critical to executing back propagation of the gradient so as to optimize our function.\n:::\n\nNow we can generate our weights and biases. We define the structure sizes with our input and output size in mind, and the principles of matrix multiplication. \n\nThe general structure we will start with will be, of course, an initial layer with one neuron for each input, which will yield a single activation per input. After a nonlinearty, the second layer will have 10 weights and biases, such that the output is a 1D vector of size 10, per input. Each output neuron will represent an estimation of likelihood that the integer is that which the neuron represents (0-9).\n\n@fig-Layer1 shows the start of the proces... A row in the input batch represents a single image. At the end of the 1^st^ layer, it is reduced to a single activation value to be passed through a non-linearity prior to going through the 2^nd^ layer\n\n![Visualizing Layer 1](Layer 1 Diagram.png){#fig-Layer1}  \n\n::: {.callout-tip }\n## Matrix Multiplication!\nNever fear! It's easy. I never forgot the trick Dr. Mohammed Jaber taught us 4th year as we had to use these methods from first year: ROW. COLUMN.\n\nTake row i from the first matrix, and column j from the second. The element in index i,j of the resulting matrix will be the dot product of that row and column vector.\n:::\n\n::: {.cell execution_count=9}\n``` {.python .cell-code code-line-numbers=\"true\"}\n# Have to provide extra dimension for matrix mutiplication, making it a single-column vector\nw1 = init_params((8*8, 1))\nb1 = init_params(1)\n# Have to provide an extra dimension (1) for matrix multiplication\nw2 = init_params((1, 10))\nb2 = init_params(1)\n```\n:::\n\n\n - Layer 1:\n    - 64 weights, one per pixel. Formatted in a column vector because they are the second term in the matrix multiplication equation, with a single input (image) being fed as a single row vector of 64 elements, one per pixel. \n    - 1 bias; it will be broadcast such that the same bias is added to all instances in our batch. See @fig-Layer1\n - Layer 2:\n    - 10 weights, to generate one output neuron per category/class to assign. \n    - 1 bias, to be *broadcast* across each input vector.^[Increasing the size of the bias vector so as to have a unique bias for each output neuron will be an opportunity to increase the capacity of the model.]\n\nWe will use the basic [ReLU](https://deepai.org/machine-learning-glossary-and-terms/relu) activation function as the non-linearity between the two linear layers.\n\n## Building the NN\n\nSimilarly to our parameter generation function, we want o make our little network into a function block so that we can treat it as a black box to plug and play with other code sections:\n\n::: {.cell execution_count=10}\n``` {.python .cell-code code-fold=\"show\" code-line-numbers=\"true\"}\ndef myModel(xb):\n    res = xb@w1+b1\n    res = res.max(tensor(0.))\n    res = res@w2+b2  # returns 10 features for each input\n    return res\n\n```\n:::\n\n\nLet's take it for a spin! We'll manually identify a subset of our training dataset for testing purposes.\n\n::: {.cell execution_count=11}\n``` {.python .cell-code code-line-numbers=\"true\"}\nmini_samp = 5\nmini_x = train_x[:mini_samp]\nmini_y = train_y[:mini_samp]\n```\n:::\n\n\n::: {.cell execution_count=12}\n``` {.python .cell-code code-fold=\"show\" code-line-numbers=\"true\"}\nres = myModel(mini_x)\nres, res.shape\n```\n\n::: {.cell-output .cell-output-display execution_count=88}\n```\n(tensor([[-0.0491, -0.0491, -0.0491, -0.0491, -0.0491, -0.0491, -0.0491, -0.0491, -0.0491, -0.0491],\n         [-0.0491, -0.0491, -0.0491, -0.0491, -0.0491, -0.0491, -0.0491, -0.0491, -0.0491, -0.0491],\n         [-0.0491, -0.0491, -0.0491, -0.0491, -0.0491, -0.0491, -0.0491, -0.0491, -0.0491, -0.0491],\n         [-0.0491, -0.0491, -0.0491, -0.0491, -0.0491, -0.0491, -0.0491, -0.0491, -0.0491, -0.0491],\n         [-0.0491, -0.0491, -0.0491, -0.0491, -0.0491, -0.0491, -0.0491, -0.0491, -0.0491, -0.0491]], grad_fn=<AddBackward0>),\n torch.Size([5, 10]))\n```\n:::\n:::\n\n\nExcellent! For the 5 input images passed in, we have an output that is 5 vectors of size 10, that is, each input has 10 output values, one for each possible classification outcome 0 through 9. \n\nAnd note that the result tensor retains the gradient! This comes into play in the next step.\n\n## Calculating Loss\n\nLoss is the measure of the neural networks success. The most critical characteristic of a loss function is that it be differentiable with a smooth gradient. But just because the math doesn't break doesn't mean the function will eb any good. There are a variety of well understood functions that can be used, with selection being a matter of preference as well as the use case at hand.\n\nSince we are assigning a single class to the input, from multiple options, we'll use the SoftMax function. It reduces all outputs to a number between 0 and 1, with a given number being exponentially closer to one, the larger it is compared to the other numbers in the set. \n\nThis is a double-hitter: it allows the net to learn to win by giving the correct digit's output neuron the highest activation, while also motivating the reduction in activation of the incorrect neurons. \n\n::: {.cell execution_count=13}\n``` {.python .cell-code code-fold=\"show\" code-line-numbers=\"true\"}\ndef my_loss(preds, target, lr=0.01):\n    maxes = F.softmax(preds, dim=-1)\n    correctIndices = [r[t] for r, t in zip(maxes, target)]\n    resy = [-torch.log(tens) for tens in correctIndices]\n    return sum(resy)\n\n```\n:::\n\n\nKeep in mind that we need to ensure these functions can work with different batch sizes. Fortunately, the PyTorch built in functions are designed for this. \n\nOur function first takes the SoftMax of the outputs for each input. Then, it pulls out the resulting value for the index of the correct class. Recall, this will be a number between 0 and 1. If we took this number alone as our loss, measure, there would be a couple of issues.\n\nFirst of all, convention is that we want to *reduce* loss in the course of our optimization. But we have defined the index of the *highest* softmax result as our classification integer. So that doesn't jive. Secondly, it isn't desirable to have the measure of loss constrained to such a small range 0 to 1, because this essentially reduces the information we're getting - large differences in inputs will show very small changes in loss. For effective learning, we would want a strong learning signal, i.e. small changes to input parameters reflecting meaningful differences in the measure of loss.\n\nThe solution? First, taking the log of the SoftMax activation. As the following code shows, a difference of 0.001 in the input to the log function creates a differences of more than 0.01 in the output, an order of magnitude difference.\n\n::: {.cell execution_count=14}\n``` {.python .cell-code code-fold=\"show\" code-line-numbers=\"true\"}\ntorch.log(Tensor([.5, .499]))\n```\n\n::: {.cell-output .cell-output-display execution_count=90}\n```\ntensor([-0.6931, -0.6951])\n```\n:::\n:::\n\n\nAfter the log, we took the negative of those values. That's because the log of a number between 0 and 1 will always be negative, getting absolutely larger the further from 1 it is. Seeing as we want the output to be absolutely smaller the closer to 1 it is, taking the negative accomplishes this perfectly.\n\nLastly, we summed the loss measure across the samples in the mini batch since we want to optimize globally, not just for individual samples.\n\nSo let's test it!\n\n::: {.cell execution_count=15}\n``` {.python .cell-code code-line-numbers=\"true\"}\n# Testing the loss function works(assuming mini_x of 3 samples)\nlossResults = my_loss(myModel(mini_x), mini_y)\nlossResults\n```\n\n::: {.cell-output .cell-output-display execution_count=91}\n```\ntensor([11.5129], grad_fn=<AddBackward0>)\n```\n:::\n:::\n\n\nThis output might look nice, but it's a roll of the dice!\n\n::: {.callout-warning}\n## Beware Of Implementing Your Own Math\nWhile the formula for the SoftMax is easy enough to understand, Our home-brewed version won't work. I tried to do so at first and had all kinds of headaches arising from arithmetic underflow in the outcomes! How the hell do you deal with that? The best solution: Use the function implementation baked into the PyTorch libraries! Let the pro's handle those *deep* issues. We're still riding on training wheels!\n:::\n\nIt turns out the `-log` of the SoftMax is the Cross Entropy Loss Function. And just importing it from the PyTorch library will save us from the pitfall described in the preceding blurb... So here is our final loss function!\n\n::: {.cell execution_count=16}\n``` {.python .cell-code code-line-numbers=\"true\"}\ndef my_loss(preds, target):\n    loss_fn = nn.CrossEntropyLoss()\n    # Turn tensor of singleton tensors one per target into a single tensor with all as elements\n    tgts = target.view(-1)\n    return loss_fn(preds, tgts)  # Nice\n```\n:::\n\n\nNow if you're reading this you're probably thinking that *gradient descent* is the next step here, so as to reduce the loss between minibatches, but we'll take a quick detour first.\n\n## Measuring Accuracy\nBefore going further, let's take a minute to set up some functions we'll need in the training process. The first yields the percentage accuracy of the model across a batch, and the second function builds on that to iterate across the batchers in our valdiation set and yield the accuracy rate across a whole epoch^[An epoch is a full pass through the entire data set, in a context where we will make multiple passes (epochs) so as to keep learning.].\n\n::: {.cell execution_count=17}\n``` {.python .cell-code code-line-numbers=\"true\"}\ndef batch_accuracy(mdl, xb, yb):\n    otpts = mdl(xb)  # Get output activations from model\n    # The indices of the max activation is the predicted digit of the input\n    preds = otpts.max(dim=-1).indices\n    # Types must be tensors to return sequence of true/false\n    correct = preds == yb.view(-1)\n    #                    Use view to take it from shape=[5,1] to [5], same as preds. else will broadcast and end result all messed up\n    return correct.float().mean()\n\n\ndef validate_epoch(mdl):\n    outcomes = [batch_accuracy(mdl, xb, yb) for xb, yb in valid_dl]\n    return round(torch.stack(outcomes).mean().item(), 4)\n\n```\n:::\n\n\nIt's always good to double check these functions are working as intended after making them... Let's grab some validation set data, double checking along the way that the outputs (integer assignment) match the input (drawings of digit):\n\n::: {.cell execution_count=18}\n``` {.python .cell-code code-line-numbers=\"true\"}\nvalidIter = iter(dls[1])\nxv, yv = next(validIter)\nfor i in range(len(xv)):\n    show_image(xv[i].view((8, 8)))\n    print(yv[i].data.item())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n1\n6\n6\n3\n3\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-19-output-2.png){width=93 height=93}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-19-output-3.png){width=93 height=93}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-19-output-4.png){width=93 height=93}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-19-output-5.png){width=93 height=93}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-19-output-6.png){width=93 height=93}\n:::\n:::\n\n\nOk nice, now lets see that our validation function is yielding the correct accuracy score on classifying a mini batch. Since we haven't trained the model yet we'll expect the performacne to be junk but that doesn't mean we can't test the % accuracy function.\n\n::: {.cell execution_count=19}\n``` {.python .cell-code code-line-numbers=\"true\"}\nvalidIter = iter(dls[1])\nxv, yv = next(validIter)\no = myModel(xv)\nprint(o.max(dim=-1).indices, yv, batch_accuracy(myModel, xv, yv))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntensor([0, 0, 0, 0, 0]) tensor([[3],\n        [8],\n        [0],\n        [5],\n        [6]]) tensor(0.2000)\n```\n:::\n:::\n\n\nWe want to see the last number spit out be an accurate representation of how many numbers match between the first and second tensor output. I don't know what the final blog output will be since the inputs to the neural net are random every time, but I re ran this code cell a number of times, seeing correct assignments of one or two integers to confirm the functions were working as expected.\n\n## Execute Training\n\nAlright now we get to the good stuff! First we'll make an iterator to load our test dataset.\n\n::: {.cell execution_count=20}\n``` {.python .cell-code code-line-numbers=\"true\"}\ntestLoader = iter(dls[0])\n```\n:::\n\n\nAnd now we we will run our first training loop... the steps are:\n\n- Define learning rate^[The learning rate is the factor by which we will multiply the gradient when adding the negative gradient to each parameter so as to update it for the next learning iteration.].\n- Pull out a minibatch of inputs and target values from the test data set.\n- Calculate the loss on this batch by passing the outputs from the model through the loss function\n- Execute the `.backward()` method to calculate the gradient for all parameters.\n- The next bits will be executed with torch.no_grad(), because we don't want the math inherent to calibrating the parameters themselves to have its gradient captured.\n- Having the gradient stored in the tensor object of each parameter, update each parameter by subtracting the gadient multiplied by the learning rate.\n- Reset the gradient to zero for the next learning iteration.\n\n::: {.cell execution_count=21}\n``` {.python .cell-code code-fold=\"show\" code-line-numbers=\"true\"}\nlr = 0.01\nxb, yb = next(testLoader)\nloss = my_loss(myModel(xb), yb)\nloss.backward()\nwith torch.no_grad():\n    for p in w1, b1, w2, b2:\n        p.data = p.data-p.grad.data*lr\n        p.grad.zero_()\nprint(\"Loss before training: \"+str(loss.item()) +\n      \"  |   Loss after training: \"+str(my_loss(myModel(xb), yb).item()))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLoss before training: 2.314004421234131  |   Loss after training: 2.3128905296325684\n```\n:::\n:::\n\n\nSuccess! Our measure of loss has reduced after re running the same batch with the adjusted N parameters. Across a large enough dataset^[The changes to parameters can be so small that the actual outcome on any single run doesn't change across a few inputs. But with enough learning iterations we will see the desired outcome.], we would expect to see a reduced error rate associated with this.\n\nLet's try it again, this time printing out the average values of the parameters in the weights and bias vectors, to get a sense for how much they change from one iteration to the next.\n\n::: {.cell execution_count=22}\n``` {.python .cell-code}\nif type(w1.grad) == NoneType:\n    print(tensor([(x.data.mean()) for x in [w1, b1, w2, b2]]))\nelse:\n    print(\"Average parameters: \", tensor(\n        [(x.data.mean(), x.grad.data.mean()) for x in [w1, b1, w2, b2]]))\n    for p in w1, b1, w2, b2:\n        p.grad.zero_()\n\n# Run the learning (copied from last cell):\nlr = 0.01\nxb, yb = next(testLoader)\nloss = my_loss(myModel(xb), yb)\nloss.backward()\nwith torch.no_grad():\n    for p in w1, b1, w2, b2:\n        p.data = p.data-p.grad.data*lr\n        p.grad.zero_()\nprint(\"Loss before training: \"+str(loss.item()) +\n      \"  |   Loss after training: \"+str(my_loss(myModel(xb), yb).item()))\n\n# Print average param values again:\nif type(w1.grad) == NoneType:\n    print(tensor([(x.data.mean()) for x in [w1, b1, w2, b2]]))\nelse:\n    print(\"Average parameters: \", tensor(\n        [(x.data.mean(), x.grad.data.mean()) for x in [w1, b1, w2, b2]]))\n    for p in w1, b1, w2, b2:\n        p.grad.zero_()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAverage parameters:  tensor([[-0.0224,  0.0000],\n        [ 0.0370,  0.0000],\n        [-0.0443,  0.0000],\n        [-0.0491,  0.0000]])\nLoss before training: 2.307793617248535  |   Loss after training: 2.3069679737091064\nAverage parameters:  tensor([[-0.0226,  0.0000],\n        [ 0.0370,  0.0000],\n        [-0.0443,  0.0000],\n        [-0.0491,  0.0000]])\n```\n:::\n:::\n\n\nWhat we see here is that our change in paramters created a reduction in the measure of loss, *even though* it wasn't even identifiable at 4 decimal points accuracy!\n\nSo let's take it to the next level. We trained on one minibatch of data. Let's try doing a whole epoch- iterating over every minibatch in the training set.\n\nFirst, we'll reset our weights to random numbers, clearing the slate of that last learning:\n\n::: {.cell execution_count=23}\n``` {.python .cell-code code-line-numbers=\"true\"}\nw1 = init_params((8*8, 1))\nb1 = init_params(1)\nw2 = init_params((1, 10))\nb2 = init_params(1)\n\n# Print average param values again:\nif type(w1.grad) == NoneType:\n    print(tensor([(x.data.mean()) for x in [w1, b1, w2, b2]]))\nelse:\n    print(\"Average parameters: \", tensor(\n        [(x.data.mean(), x.grad.data.mean()) for x in [w1, b1, w2, b2]]))\n    for p in w1, b1, w2, b2:\n        p.grad.zero_()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntensor([ 0.0039,  0.1684,  0.0347, -0.0492])\n```\n:::\n:::\n\n\nAnd now execute learning.\n\n::: {.cell execution_count=24}\n``` {.python .cell-code code-fold=\"show\" code-line-numbers=\"true\"}\nlr = 0.01\nfor xb, yb in dls[0]:\n    loss = my_loss(myModel(xb), yb)\n    loss.backward()\n    with torch.no_grad():\n        for p in w1, b1, w2, b2:\n            p.data = p.data-p.grad.data*lr\n            p.grad.zero_()\n    print(\"Loss: \"+str(loss.item()))  # Prints loss for each minibatch\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLoss: 2.199075937271118\nLoss: 2.2563600540161133\nLoss: 2.2406294345855713\nLoss: 2.255134344100952\nLoss: 2.3489809036254883\nLoss: 2.2468106746673584\nLoss: 2.2854390144348145\nLoss: 2.2784039974212646\nLoss: 2.376652717590332\nLoss: 2.32565975189209\nLoss: 2.2398929595947266\nLoss: 2.3289480209350586\nLoss: 2.2844693660736084\nLoss: 2.2962541580200195\nLoss: 2.2766005992889404\nLoss: 2.2820425033569336\nLoss: 2.208583116531372\nLoss: 2.2875723838806152\nLoss: 2.2431399822235107\nLoss: 2.2146613597869873\nLoss: 2.203139305114746\nLoss: 2.2511353492736816\nLoss: 2.165519952774048\nLoss: 2.128993511199951\nLoss: 2.2865686416625977\nLoss: 2.320838689804077\nLoss: 2.237919807434082\nLoss: 2.288886785507202\nLoss: 2.1258111000061035\nLoss: 2.175995111465454\nLoss: 2.274925708770752\nLoss: 2.125221014022827\nLoss: 2.3225929737091064\nLoss: 2.2280237674713135\nLoss: 2.1571156978607178\nLoss: 2.1414029598236084\nLoss: 2.1865856647491455\nLoss: 2.2655110359191895\nLoss: 2.188227653503418\nLoss: 2.2199552059173584\nLoss: 2.3190643787384033\nLoss: 2.2241218090057373\nLoss: 2.222172975540161\nLoss: 2.2191574573516846\nLoss: 2.1026976108551025\nLoss: 2.240053653717041\nLoss: 2.174922227859497\nLoss: 2.0920538902282715\nLoss: 2.1837966442108154\nLoss: 2.2589786052703857\nLoss: 2.058783769607544\nLoss: 2.119903802871704\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nLoss: 2.1753287315368652\nLoss: 2.136204481124878\nLoss: 2.1862473487854004\nLoss: 2.1653738021850586\nLoss: 2.1605117321014404\nLoss: 2.150763988494873\nLoss: 2.1495931148529053\nLoss: 2.20322322845459\nLoss: 2.0865442752838135\nLoss: 2.222790479660034\n```\n:::\n:::\n\n\nHmmm.... sometimes when I run this I see the loss stay around the same value, other times it drops just a little before stabilizing... \n\nWe are going to need a better way to look at the trending of the loss function across iterations, so we may as well make that function now:\n\n::: {.cell execution_count=25}\n``` {.python .cell-code code-fold=\"show\" code-line-numbers=\"true\"}\ndef calc_grad(xb, yb, model, f_loss):\n    preds = model(xb)\n    loss = f_loss(preds, yb)\n    loss.backward()\n    return loss.data.item()  # Return the loss (see why later)\n\n\ncalc_grad(mini_x, mini_y, myModel, my_loss)\n```\n\n::: {.cell-output .cell-output-display execution_count=101}\n```\n2.3867080211639404\n```\n:::\n:::\n\n\nThis is another step towards modularizing (if that is a word) our code. Making use of that last function, our training loop now looks like this:\n\n::: {.cell execution_count=26}\n``` {.python .cell-code code-fold=\"show\" code-line-numbers=\"true\"}\n# Initializing weights again for a fresh start\nw1 = init_params((8*8, 1))\nb1 = init_params(1)\nw2 = init_params((1, 10))\nb2 = init_params(1)\n\nprint(\"PreTrain Accuracy: \"+str(validate_epoch(myModel)))\n\n\ndef train_epoch(model, lr, params, f_loss):\n    for xb, yb in dls[0]:\n        calc_grad(xb, yb, model, f_loss)\n        with torch.no_grad():\n            for p in w1, b1, w2, b2:\n                p.data = p.data-p.grad.data*lr\n                p.grad.zero_()\n\n\ntrain_epoch(myModel, 0.01, [w1, b1, w2, b2], my_loss)\nprint(\"PostTrain Accuracy: \"+str(validate_epoch(myModel)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nPreTrain Accuracy: 0.195\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nPostTrain Accuracy: 0.2\n```\n:::\n:::\n\n\nUH OH!\n\n::: {.callout-note collapse=\"true\"}\n## Overfitting\n\nOur loss is going down, but our error is erratic, staying the same, or going up! This is an indicator that we've reached a point where the mathematical strategy we're using to optimize is now playing games with us. The modifications *do* reduce loss, but that is no longer aligned with an improvement with the task. Recall that a loss function *should* always correlate with NN efficacy, but this can break down at the fringes.\n:::\n\nIs this a problem? Yes! But one that can be solved. Overall we are still in good territory.. We know the math and programming is working from a nuts and bolts perspective. What this indicates to us is that we need to tune the *metaparameters* of our neural network function. How many layers are there? How wide are the layers? We may be in a situation where the NN doesn't have sufficient *capacity*^[(Further reading)[https://machinelearningmastery.com/how-to-control-neural-network-model-capacity-with-nodes-and-layers/] on capacity.] to get us the outcomes we're looking for.\n\n## Building Test Infrastructure\n\nWe've built an NN from first principles now, putting together the building blocks of parameter initialization, running the algebra through the net, backpropagation to compute the gradient, and parameter calibration through the gradient descent method. This all executing repeatedly across batches of data.\n\nBefore we adjust the network structure to optimize the outcomes, let's define a yet higher encapsulation of these tools to further condense the commands needed to execute this whole process, as well as enable more execution flexibility. This is where the `BasicOptim` class omes in:\n\n::: {.cell execution_count=27}\n``` {.python .cell-code code-fold=\"show\" code-line-numbers=\"true\"}\nclass BasicOptim:\n    def __init__(self, params, lr): self.params, self.lr = list(params), lr\n\n    def step(self, *args, **kwargs):\n        for p in self.params:\n            p.data -= p.grad.data * self.lr\n\n    def zero_grad(self, *args, **kwargs):\n        for p in self.params:\n            p.grad = None\n```\n:::\n\n\nNow, we can condense the training loop, and also neatly add the function of tracking loss across batches.\n\n::: {.cell execution_count=28}\n``` {.python .cell-code code-fold=\"show\" code-line-numbers=\"true\"}\ndef train_epoch(model, opt, lr, params, f_loss):\n    losses = []  # Will allow for recording epoch wise loss\n    for xb, yb in dls[0]:\n        calc_grad(xb, yb, model, f_loss)\n        opt.step()\n        losses.append(calc_grad(xb, yb, model, f_loss))\n        opt.zero_grad()\n    return tensor(losses)\n\n```\n:::\n\n\nAnd per usual, give it a test:\n\n::: {.cell execution_count=29}\n``` {.python .cell-code code-fold=\"show\" code-line-numbers=\"true\"}\nmy_opt = BasicOptim([w1, b1, w2, b2], 0.01)\nres = train_epoch(myModel, my_opt, 0.01, [w1, b1, w2, b2], my_loss)\nres.mean(), res\n```\n\n::: {.cell-output .cell-output-display execution_count=105}\n```\n(tensor(2.0876),\n tensor([2.1980, 2.1252, 2.1773, 2.1694, 2.1912, 2.2293, 2.1469, 2.0619, 2.1294, 2.1239, 2.0797, 2.0302, 2.0124, 2.0873, 2.0908, 2.0695, 2.2541, 2.0502, 2.0780, 2.2446, 2.0911, 2.0455, 2.1385, 2.1759,\n         1.9776, 2.0968, 2.0866, 2.0702, 2.0632, 2.1360, 2.0806, 2.0838, 2.0376, 2.0701, 1.8794, 2.1304, 2.0233, 1.9755, 2.0896, 2.0513, 2.0882, 2.0572, 2.1628, 2.0935, 2.1328, 1.9948, 2.1807, 2.1097,\n         1.9890, 2.0817, 2.1764, 2.1576, 1.9863, 2.0150, 2.0294, 2.1838, 1.9823, 2.0590, 2.0871, 2.1473, 1.8388, 2.0286]))\n```\n:::\n:::\n\n\nGreat: bug free. But... still this issue of the loss bouncing around withot a clear improvement trend...\n\nKnowing that I want to experiment with the models metaprameters to improve it, I'll finally define yet another object to contain those we've made so far and run trials with customized parameters, and providing the means for monitoring these trials more easily.\n\n::: {.cell execution_count=30}\n``` {.python .cell-code code-fold=\"show\" code-line-numbers=\"true\"}\nclass cTrial:\n    def __init__(self, numE=10, lr=0.01, model=myModel, opt=my_opt, params=[w1, b1, w2, b2], f_loss=my_loss):\n        self.numE = numE\n        self.lr = lr\n        self.model = model\n        self.opt = opt\n        self.params = params\n        self.f_loss = f_loss\n        self.res = []\n        self.valids = []\n        self.wtsHist = []  # For tracking change in weights across learning\n\n    def run(self, numE=None, wkLr=None):\n        self.valids = []  # Reset\n        epch_losses = []  # Reset\n        self.wtsHist = [[], [], [], []]  # 4 contents, w1,b1,w2,b2\n        if numE is None:\n            numE = self.numE\n        if wkLr is None:\n            wkLr = self.lr\n        for i in range(numE):\n            # -- Record wts for analysis\n            self.wtsHist[0].append(list(x.item() for x in w1.data.view(-1)))\n            self.wtsHist[1].append(list(x.item() for x in b1.data.view(-1)))\n            self.wtsHist[2].append(list(x.item() for x in w2.data.view(-1)))\n            self.wtsHist[3].append(list(x.item() for x in b2.data.view(-1)))\n            # --\n            res = train_epoch(self.model, self.opt, self.lr,\n                              self.params, self.f_loss)\n            epch_losses.append(res)\n            self.valids.append(validate_epoch(self.model))\n        self.res = torch.stack(epch_losses)\n        self.valids = tensor(self.valids)\n\n```\n:::\n\n\nThis object allows for defining all the parameters necessary for a trial, and then running it one line of code, alternaitvely overwriting the number of Epochs, and learning rate parameters.\n\n## Experimenting To Optimize NN\n\nLet's get into it. We make a trial object and run it:\n\n::: {.cell execution_count=31}\n``` {.python .cell-code code-fold=\"show\" code-line-numbers=\"true\"}\nmy_try = cTrial()\nmy_try.run(numE=50, wkLr=0.001)\nmy_try.res.shape\n```\n\n::: {.cell-output .cell-output-display execution_count=107}\n```\ntorch.Size([50, 62])\n```\n:::\n:::\n\n\nOur functions are logging loss for each mini batch across all epochs. So this makes sense. We had 1540 data points, with minibatches of 25. `25*62=1550`, so we have 61 minibatches of 25 one last minibatch of 15. And 50 collections of 62, one for each epoch.\n\n### First Try\n\nSo let's see the results by taking the average loss across each epoch, hopefully, it'll be dropping!\n\n::: {.cell execution_count=32}\n``` {.python .cell-code code-line-numbers=\"true\"}\nplt.plot(my_try.res.mean(dim=1))\n```\n\n::: {.cell-output .cell-output-display}\n![Average loss across epochs](index_files/figure-html/fig-loss1-output-1.png){#fig-loss1 width=585 height=414}\n:::\n:::\n\n\nSo loss is going down, it's working right? The real test isn't reduction to our measure loss, but to see that carry through to an increase in testing accuracy:\n\n::: {.cell execution_count=33}\n``` {.python .cell-code code-line-numbers=\"true\"}\nplt.plot(my_try.valids)\n```\n\n::: {.cell-output .cell-output-display}\n![Prediction accuracy across epochs](index_files/figure-html/fig-val1-output-1.png){#fig-val1 width=595 height=414}\n:::\n:::\n\n\nDisaster strikes! We're never getting more than 20% accuracy! Well, they call it *deep learning*, so let's make our model deeper. Two layers? A pittance!\n\n### Second Try\n\nOur Model V2 will look like this:\n\n - 64 input activations (image pixels) to 32 neurons in the first layer, with a unique (not broadcasted) bias for each neuron\n - The next layer will reduce the 32 neurons to 16, with anothe runique bias for each\n - The next will reduce teh 16 layers to 10 (output layer activations) with a unique bias for each\n - Between each layer we will use the ReLu for nonlinearity.\n\n::: {.callout-tip collapse=\"true\"}\n## Visualizing V2 Of Our NN\nCan you picture the matrix multiplication? It's important to get it straight! What would the equivalent of @fig-Layer1 look like for our NN V2?\n\n:::\n\nDefining parameters:\n\n::: {.cell execution_count=34}\n``` {.python .cell-code code-fold=\"show\" code-line-numbers=\"true\"}\n# Initialize parameters using the functions defined above to make it easy to generate variously sized tensors\nW1 = init_params((8*8, 32))  # 64 in, 32 out\nB1 = init_params(32)  # Feature-specific biases added\nW2 = init_params((32, 16))  # 32 in, 16 out\nB2 = init_params(16)  # Feature-specific biases added\nW3 = init_params((16, 10))  # 16 in, 10 out\nB3 = init_params(10)  # Feature-specific biases added\n```\n:::\n\n\nDefine the model:\n\n::: {.cell execution_count=35}\n``` {.python .cell-code code-fold=\"show\" code-line-numbers=\"true\"}\ndef mdlV2(xb):\n    res = xb@W1+B1\n    res = res.max(tensor(0.))\n    res = res@W2+B2  # returns 10 features for each input\n    res = res.max(tensor(0.))\n    res = res@W3+B3  # returns 10 features for each input\n    return res\n\n```\n:::\n\n\nTest it with a mini sample to ensure the Tensors were defined in the correct size to achieve our purpose:\n\n::: {.cell execution_count=36}\n``` {.python .cell-code code-line-numbers=\"true\"}\nmdlV2(mini_x)\n```\n\n::: {.cell-output .cell-output-display execution_count=112}\n```\ntensor([[-0.2428,  0.5232, -0.7904, -0.7885, -0.3272, -0.0872, -0.2902,  0.4390, -0.2662,  1.2232],\n        [-0.5748,  0.5424, -1.3543, -0.7292, -0.3614,  0.0895, -0.2838,  0.4246, -0.1013,  1.0879],\n        [-0.5503,  0.4186, -1.0044, -0.9231,  0.2918,  0.0088, -0.4464,  0.1199,  0.0782,  0.6630],\n        [-0.3652,  0.5230, -0.9236, -1.1226, -0.3005,  0.1551, -0.5508,  0.6067, -0.5363,  1.1322],\n        [-0.5096,  0.5700, -1.0935, -0.7603, -0.0838,  0.0959, -0.1930,  0.2362, -0.0920,  1.0207]], grad_fn=<AddBackward0>)\n```\n:::\n:::\n\n\nRun it!\n\n:::{#fig-V2}\n\n::: {.cell .column-page execution_count=37}\n``` {.python .cell-code code-line-numbers=\"true\"}\nmy_try = cTrial(model=mdlV2, opt=BasicOptim(\n    [W1, B1, W2, B2, W3, B3], 0.01), params=[W1, B1, W2, B2, W3, B3])\nmy_try.run(numE=20, wkLr=20)\nplt.plot(my_try.res.mean(dim=1)[1:])\nplt.plot(my_try.valids)\nplt.plot([0.9 for x in my_try.valids])\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-38-output-1.png){width=575 height=414}\n:::\n:::\n\n\nAccuracy Increasing As Loss Reduces\n\n:::\n\nFantastic! Like an Olympic high jumper, we vault just over the top of the target! Time for champagne?! Not so fast! These results are those from exeucting on the training set. Remember when we partitioned off the validation set? Let's see how the model does on that data.\n\nThe point of a validation set is to increase cofnidence that our model hasn't faux-optimized by 'playing our game' so to speak, and learning to score well on test data while not actually generalizing across the domain of all possible inputs\n\n::: {.cell execution_count=38}\n``` {.python .cell-code code-fold=\"show\" code-line-numbers=\"true\"}\ndef confMtx(model):\n    conf = torch.zeros([10, 10], dtype=torch.int32)\n    for xv, yv in dls[1]:\n        preds = model(xv).max(dim=-1).indices\n        for i in range(len(xv)):\n            conf[yv[i].item()][preds[i].item()] += 1\n    df = pd.DataFrame(conf)\n    df.style.set_properties(**{'font-size': '6pt'}\n                            ).background_gradient('Greys')\n    df.style.set_table_styles([dict(selector='th', props=[(\n        'text-align', 'center')])]).set_properties(**{'text-align': 'center'})\n    df.style.set_caption(\"Top Axis: Predicted value. Left Axis: Actual Value\")\n    return df\n\n    # return df\nconfMtx(mdlV2)\n```\n\n::: {.cell-output .cell-output-display execution_count=114}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>16</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>20</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>20</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>14</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>17</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>20</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>18</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>17</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>16</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>11</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}