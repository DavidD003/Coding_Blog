{
  "hash": "8e67020f42840fd99df415a824d3a21f",
  "result": {
    "markdown": "---\ntitle: \"A Simple Digit Classifier\"\nauthor: \"David De Sa\"\ndate: \"2023-03-14\"\ncategories: [python, pyTorch, NeuralNetworks]\nimage: \"NN101_thumbnail.png\"\nformat:\n  html:\n    code-fold: true\n    toc: true\n    code-tools: true\ndraft: true\n---\n\n## TL;DR\nThe best way to learn is to teach, so in this post I try to teach the reader how my first neural network implementation works! Part 2 of 2. I built this in following along with the awesome lessons over at [fast.ai](course.fast.ai). Many thanks to that team.\n\n# Overview\nWe're going to jump in where we left off in Part 1: We'll just reimport our data, and get into it.\n\n### What?\nWe're going to create a neural network that, given a picture of a numeric digit, identifies the number.\n\n### Why?\nDoes this really need explaining? Because the technology is amazing in both practical and philosophical ways.\n\n### Who?\n[Who am I](https://davidd003.github.io/Coding_Blog/about.html)!? Who are you?!\n\n### How?\nUsing [PyTorch](https://pytorch.org/)^[If it ain't 'py', it ain't python, right?], an opensource toolkit for building neural networks. Truly an elevator ride up onto the shoulders of giants.\n\n# Code Review\nWe'll first just re-import our data, and then get into building the groundwork for our neural network\n\nLet's get into it!\n\n::: {.callout-note collapse=\"true\"}\nThe required dependencies!:`scikit-learn`, `fastbook`, `matplotlib`\n:::\n\n::: {.cell execution_count=1}\n``` {.python .cell-code code-line-numbers=\"true\"}\n# Install dependency\nfrom fastbook import *\nfrom fastai.vision.all import *\nfrom sklearn.datasets import load_digits\nimport fastbook\n\nfastbook.setup_book()\n\n\nmatplotlib.rc(\"image\", cmap=\"Greys\")\n```\n:::\n\n\n## Data Acquisition\nA quick flashback to Part 1 of my Building A Digit Classifier blog!:\n\n::: {.callout-tip collapse=\"true\"}\n## Understand Your Input!\n\nPre-processing data before even touching any neural net methods can improve your final performance. Note the data set information offered at the [source page](https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits): \n\n> We used preprocessing programs made available by NIST to extract normalized bitmaps of handwritten digits from a preprinted form. From a total of 43 people, 30 contributed to the training set and different 13 to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of 4x4 and the number of on pixels are counted in each block. This generates an input matrix of 8x8 where each element is an integer in the range 0..16. This reduces dimensionality and gives invariance to small distortions.\n:::\n\n::: {.cell execution_count=2}\n``` {.python .cell-code code-line-numbers=\"true\"}\nmnist = load_digits()\nstacked = []\n# This loop because stacked=[[]]*10 makes 1 list in list, with 10 copies of pointers... need separate objects\nfor i in range(10):\n    stacked.append([])\n# Assign all images to the right collection in the 'stacked' list, indexed by target\nfor i in range(len(mnist[\"target\"])):\n    stacked[mnist[\"target\"][i]].append(mnist[\"images\"][i])\n```\n:::\n\n\n### Segmentation\nThe next step is to define which data will be our training, and our validation set. It was important to bucket out our data first so by randomly sampling our data we didn't generate a validation set with a large imbalance in the number of classes to be tested in it. \n\nFirst we convert to a tensor, then segment training from validation data. Arbitrarily taking 20 examples from each digit, so, 11.5% of the total data set towards validation.\n\nWe'll print out the size of these collections and take a peek at a sample to make sure we indexed right.\n\n:::{#fig-checkSamp}\n\n::: {.cell execution_count=3}\n``` {.python .cell-code code-line-numbers=\"true\"}\n# To make dataset a tensor, make it same number of dimensions\nstacked = tensor([x[:174] for x in stacked])\n# Segmentation: Pull 20 of each digit out of training set\ntest = [dig[-20:] for dig in stacked]\ntrain = [dig[:-20] for dig in stacked]\n# Confirm counts of samples\n[len(test[i]) for i in range(10)], [len(train[i]) for i in range(10)]\nshow_image(stacked[3][0])  # Check sample\n```\n\n::: {.cell-output .cell-output-display execution_count=29}\n```\n<Axes: >\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-4-output-2.png){width=93 height=93}\n:::\n:::\n\n\nIs it a 3?\n:::\nNice.\n\nIt's important to keep track of what's what.\n\n::: {.cell execution_count=4}\n``` {.python .cell-code code-fold=\"show\" code-line-numbers=\"true\"}\ntype(train), type(train[0]), type(train[0][0]), [\n    type(test), type(test[0]), type(test[0][0])]\n```\n\n::: {.cell-output .cell-output-display execution_count=30}\n```\n(list, torch.Tensor, torch.Tensor, [list, torch.Tensor, torch.Tensor])\n```\n:::\n:::\n\n\nOk so our top level containers for training/testing data are basic python lists. Within those, we have 10 collections, one for each integer. Those are Tensors. And then, each image (a collection of pixels unto itself) within those tensors, are also Tensor type objects.\n\nInstead of a basic Python list, we will need the top level containers as tensors to leverage the pyTorch functionality built into them. luckily it's an easy conversion:\n\n::: {.cell execution_count=5}\n``` {.python .cell-code code-line-numbers=\"true\"}\n# Converts PyList of tensors to tensor of tesnors (join in new dimensions, retain target indexing)\ntrain = torch.stack(train)\ntest = torch.stack(test)\ntrain.shape, test.shape\n```\n\n::: {.cell-output .cell-output-display execution_count=31}\n```\n(torch.Size([10, 154, 8, 8]), torch.Size([10, 20, 8, 8]))\n```\n:::\n:::\n\n\nNow here is a critical piece, working with multidimensional arrays and keeping in mind what we understand these to be. Our test and training tensors have the same dimensionality but not the same size. \n\n### Setup DataLoaders\nFirst get data into the requisite shape for the processes that will follow. \n\n::: {.cell execution_count=6}\n``` {.python .cell-code code-line-numbers=\"true\"}\n# Build training/valid sets for passing to DataLoader\ntrain_x = torch.cat([x for x in train]).view(-1, 8*8)\ntest_x = torch.cat([x for x in test]).view(-1, 8*8)\ntrain_y, test_y = [], []\nfor n in range(10):\n    train_y.extend([n]*154)\n    test_y.extend([n]*20)\ntrain_y = tensor(train_y).unsqueeze(-1)\ntest_y = tensor(test_y).unsqueeze(-1)\ntrain_x.shape, test_x.shape, train_y.shape, test_y.shape\n```\n\n::: {.cell-output .cell-output-display execution_count=32}\n```\n(torch.Size([1540, 64]),\n torch.Size([200, 64]),\n torch.Size([1540, 1]),\n torch.Size([200, 1]))\n```\n:::\n:::\n\n\nNote the unsqueezing such that the `_y` tensors have a singleton dimension. Might seem strange on first blush but makes sense when considering that our 'target' just happens to be individual integers. But in other use cases, the target could be something more complex, requiring a larger data structure. In which case that dimension could be larger than a singleton.\n\nNow we can prime our DataLoaders. DataLoaders are a super handy object from the Pytorch library that will make life easier by holding our data for us, and serving it up in randomized batches.\n\n::: {.cell execution_count=7}\n``` {.python .cell-code code-line-numbers=\"true\"}\n# Zip each input data item to its target output\ndset = list(zip(train_x, train_y))\nvalid_dset = list(zip(test_x, test_y))\n# Define DataLoader objects to pass to learner\ndl = DataLoader(dset, batch_size=25, shuffle=true)\nvalid_dl = DataLoader(valid_dset, batch_size=5, shuffle=true)\n\ndls = DataLoaders(dl, valid_dl)\n```\n:::\n\n\n## Laying The NN Foundations\nEvery NN needs weights and biases. We're going to want to initialize lots of them, and in differently shaped structures, so first we define a function to help us do that:\n\n::: {.cell execution_count=8}\n``` {.python .cell-code code-line-numbers=\"true\"}\ndef init_params(size, std=.1): return (torch.randn(size)*std).requires_grad_()\n\n```\n:::\n\n\n::: {.callout-note collapse=\"true\"}\n## Requiring Grad!\nNote that any memory structures created with that function will also store their gradient in memory as computation is performed on them. This will be critical to executing back propagation of the gradient so as to optimize our function.\n:::\n\nNow we can generate our weights and biases. We define the structure sizes with our input and output size in mind, and the principles of matrix multiplication. \n\nThe general structure we will start with will be, of course, an initial layer with one neuron for each input, which will yield a single activation per input. After a nonlinearty, the second layer will have 10 weights and biases, such that the output is a 1D vector of size 10, per input. Each output neuron will represent an estimation of likelihood that the integer is that which the neuron represents (0-9).\n\n@fig-Layer1 shows the start of the proces... A row in the input batch represents a single image. At the end of the 1^st^ layer, it is reduced to a single activation value to be passed through a non-linearity prior to going through the 2^nd^ layer\n\n![Visualizing Layer 1](Layer 1 Diagram.png){#fig-Layer1}  \n\n::: {.callout-tip }\n## Matrix Multiplication!\nNever fear! It's easy. I never forgot the trick Dr. Mohammed Jaber taught us 4th year as we had to use these methods from first year: ROW. COLUMN.\n\nTake row i from the first matrix, and column j from the second. The element in index i,j of the resulting matrix will be the dot product of that row and column vector.\n:::\n\n::: {.cell execution_count=9}\n``` {.python .cell-code code-line-numbers=\"true\"}\n# Have to provide extra dimension for matrix mutiplication, making it a single-column vector\nw1 = init_params((8*8, 1))\nb1 = init_params(1)\n# Have to provide an extra dimension (1) for matrix multiplication\nw2 = init_params((1, 10))\nb2 = init_params(1)\n```\n:::\n\n\n - Layer 1:\n    - 64 weights, one per pixel. Formatted in a column vector because they are the second term in the matrix multiplication equation, with a single input (image) being fed as a single row vector of 64 elements, one per pixel. \n    - 1 bias; it will be broadcast such that the same bias is added to all instances in our batch. See @fig-Layer1\n - Layer 2:\n    - 10 weights, to generate one output neuron per category/class to assign. \n    - 1 bias, to be *broadcast* across each input vector.^[Increasing the size of the bias vector so as to have a unique bias for each output neuron will be an opportunity to increase the capacity of the model.]\n\nWe will use the basic [ReLU](https://deepai.org/machine-learning-glossary-and-terms/relu) activation function as the non-linearity between the two linear layers.\n\n## Building the NN\n\nSimilarly to our parameter generation function, we want o make our little network into a function block so that we can treat it as a black box to plug and play with other code sections:\n\n::: {.cell execution_count=10}\n``` {.python .cell-code code-fold=\"show\" code-line-numbers=\"true\"}\ndef myModel(xb):\n    res = xb@w1+b1\n    res = res.max(tensor(0.))\n    res = res@w2+b2  # returns 10 features for each input\n    return res\n\n```\n:::\n\n\nLet's take it for a spin! We'll manually identify a subset of our training dataset for testing purposes.\n\n::: {.cell execution_count=11}\n``` {.python .cell-code code-line-numbers=\"true\"}\nmini_samp = 5\nmini_x = train_x[:mini_samp]\nmini_y = train_y[:mini_samp]\n```\n:::\n\n\n::: {.cell execution_count=12}\n``` {.python .cell-code code-fold=\"show\" code-line-numbers=\"true\"}\nres = myModel(mini_x)\nres, res.shape\n```\n\n::: {.cell-output .cell-output-display execution_count=38}\n```\n(tensor([[ 0.0392,  0.0968, -0.1264, -0.0286, -0.1667, -0.0667, -0.0731,  0.0230, -0.0675, -0.1758],\n         [ 0.2856,  0.4509, -0.1896,  0.0910, -0.3052, -0.0182, -0.0367,  0.2391, -0.0206, -0.3315],\n         [ 0.1481,  0.2533, -0.1544,  0.0243, -0.2279, -0.0452, -0.0570,  0.1185, -0.0468, -0.2446],\n         [-0.0926, -0.0926, -0.0926, -0.0926, -0.0926, -0.0926, -0.0926, -0.0926, -0.0926, -0.0926],\n         [ 0.2645,  0.4205, -0.1842,  0.0808, -0.2933, -0.0223, -0.0399,  0.2206, -0.0246, -0.3181]], grad_fn=<AddBackward0>),\n torch.Size([5, 10]))\n```\n:::\n:::\n\n\nExcellent! For the 5 input images passed in, we have an output that is 5 vectors of size 10, that is, each input has 10 output values, one for each possible classification outcome 0 through 9. \n\nAnd note that the result tensor retains the gradient! This comes into play in the next step.\n\n## Calculating Loss\n\nLoss is the measure of the neural networks success. The most critical characteristic of a loss function is that it be differentiable with a smooth gradient. But just because the math doesn't break doesn't mean the function will eb any good. There are a variety of well understood functions that can be used, with selection being a matter of preference as well as the use case at hand.\n\nSince we are assigning a single class to the input, from multiple options, we'll use the SoftMax function. It reduces all outputs to a number between 0 and 1, with a given number being exponentially closer to one, the larger it is compared to the other numbers in the set. \n\nThis is a double-hitter: it allows the net to learn to win by giving the correct digit's output neuron the highest activation, while also motivating the reduction in activation of the incorrect neurons. \n\n::: {.cell execution_count=13}\n``` {.python .cell-code code-fold=\"show\" code-line-numbers=\"true\"}\ndef my_loss(preds, target, lr=0.01):\n    maxes = F.softmax(preds, dim=-1)\n    correctIndices = [r[t] for r, t in zip(maxes, target)]\n    resy = [-torch.log(tens) for tens in correctIndices]\n    return sum(resy)\n\n```\n:::\n\n\nKeep in mind that we need to ensure these functions can work with different batch sizes. Fortunately, the PyTorch built in functions are designed for this. \n\nOur function first takes the SoftMax of the outputs for each input. Then, it pulls out the resulting value for the index of the correct class. Recall, this will be a number between 0 and 1. If we took this number alone as our loss, measure, there would be a couple of issues.\n\nFirst of all, convention is that we want to *reduce* loss in the course of our optimization. But we have defined the index of the *highest* softmax result as our classification integer. So that doesn't jive. Secondly, it isn't desirable to have the measure of loss constrained to such a small range 0 to 1, because this essentially reduces the information we're getting - large differences in inputs will show very small changes in loss. For effective learning, we would want a strong learning signal, i.e. small changes to input parameters reflecting meaningful differences in the measure of loss.\n\nThe solution? First, taking the log of the SoftMax activation. As the following code shows, a difference of 0.001 in the input to the log function creates a differences of more than 0.01 in the output, an order of magnitude difference.\n\n::: {.cell execution_count=14}\n``` {.python .cell-code code-fold=\"show\" code-line-numbers=\"true\"}\ntorch.log(Tensor([.5, .499]))\n```\n\n::: {.cell-output .cell-output-display execution_count=40}\n```\ntensor([-0.6931, -0.6951])\n```\n:::\n:::\n\n\nAfter the log, we took the negative of those values. That's because the log of a number between 0 and 1 will always be negative, getting absolutely larger the further from 1 it is. Seeing as we want the output to be absolutely smaller the closer to 1 it is, taking the negative accomplishes this perfectly.\n\nLastly, we summed the loss measure across the samples in the mini batch since we want to optimize globally, not just for individual samples.\n\nSo let's test it!\n\n::: {.cell execution_count=15}\n``` {.python .cell-code code-line-numbers=\"true\"}\n# Testing the loss function works(assuming mini_x of 3 samples)\nlossResults = my_loss(myModel(mini_x), mini_y)\nlossResults\n```\n\n::: {.cell-output .cell-output-display execution_count=41}\n```\ntensor([10.7966], grad_fn=<AddBackward0>)\n```\n:::\n:::\n\n\nThis output might look nice, but it's a roll of the dice!\n\n::: {.callout-warning}\n## Beware Of Implementing Your Own Math\nWhile the formula for the SoftMax is easy enough to understand, Our home-brewed version won't work. I tried to do so at first and had all kinds of headaches arising from arithmetic underflow in the outcomes! How the hell do you deal with that? The best solution: Use the function implementation baked into the PyTorch libraries! Let the pro's handle those *deep* issues. We're still riding on training wheels!\n:::\n\nIt turns out the `-log` of the SoftMax is the Cross Entropy Loss Function. And just importing it from the PyTorch library will save us from the pitfall described in the preceding blurb... So here is our final loss function!\n\n::: {.cell execution_count=16}\n``` {.python .cell-code code-line-numbers=\"true\"}\ndef my_loss(preds, target):\n    loss_fn = nn.CrossEntropyLoss()\n    # Turn tensor of singleton tensors one per target into a single tensor with all as elements\n    tgts = target.view(-1)\n    return loss_fn(preds, tgts)  # Nice\n```\n:::\n\n\nNow if you're reading this you're probably thinking that *gradient descent* is the next step here, so as to reduce the loss between minibatches, but we'll take a quick detour first.\n\n## Measuring Accuracy\nBefore going further, let's take a minute to set up some functions we'll need in the training process. The first yields the percentage accuracy of the model across a batch, and the second function builds on that to iterate across the batchers in our valdiation set and yield the accuracy rate across a whole epoch^[An epoch is a full pass through the entire data set, in a context where we will make multiple passes (epochs) so as to keep learning.].\n\n::: {.cell execution_count=17}\n``` {.python .cell-code code-line-numbers=\"true\"}\ndef batch_accuracy(mdl, xb, yb):\n    otpts = mdl(xb)  # Get output activations from model\n    # The indices of the max activation is the predicted digit of the input\n    preds = otpts.max(dim=-1).indices\n    # Types must be tensors to return sequence of true/false\n    correct = preds == yb.view(-1)\n    #                    Use view to take it from shape=[5,1] to [5], same as preds. else will broadcast and end result all messed up\n    return correct.float().mean()\n\n\ndef validate_epoch(mdl):\n    outcomes = [batch_accuracy(mdl, xb, yb) for xb, yb in valid_dl]\n    return round(torch.stack(outcomes).mean().item(), 4)\n\n```\n:::\n\n\nIt's always good to double check these functions are working as intended after making them... Let's grab some validation set data, double checking along the way that the outputs (integer assignment) match the input (drawings of digit):\n\n::: {.cell execution_count=18}\n``` {.python .cell-code code-line-numbers=\"true\"}\nvalidIter = iter(dls[1])\nxv, yv = next(validIter)\nfor i in range(len(xv)):\n    show_image(xv[i].view((8, 8)))\n    print(yv[i].data.item())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n8\n3\n0\n2\n5\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-19-output-2.png){width=93 height=93}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-19-output-3.png){width=93 height=93}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-19-output-4.png){width=93 height=93}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-19-output-5.png){width=93 height=93}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-19-output-6.png){width=93 height=93}\n:::\n:::\n\n\nOk nice, now lets see that our validation function is yielding the correct accuracy score on classifying a mini batch. Since we haven't trained the model yet we'll expect the performacne to be junk but that doesn't mean we can't test the % accuracy function.\n\n::: {.cell execution_count=19}\n``` {.python .cell-code code-line-numbers=\"true\"}\nvalidIter = iter(dls[1])\nxv, yv = next(validIter)\no = myModel(xv)\nprint(o.max(dim=-1).indices, yv, batch_accuracy(myModel, xv, yv))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntensor([1, 1, 1, 1, 1]) tensor([[8],\n        [7],\n        [2],\n        [2],\n        [8]]) tensor(0.)\n```\n:::\n:::\n\n\nWe want to see the last number spit out be an accurate representation of how many numbers match between the first and second tensor output. I don't know what the final blog output will be since the inputs to the neural net are random every time, but I re ran this code cell a number of times, seeing correct assignments of one or two integers to confirm the functions were working as expected.\n\n## Execute Training\n\nAlright now we get to the good stuff! First we'll make an iterator to load our test dataset.\n\n::: {.cell execution_count=20}\n``` {.python .cell-code code-line-numbers=\"true\"}\ntestLoader = iter(dls[0])\n```\n:::\n\n\nAnd now we we will run our first training loop... the steps are:\n\n- Define learning rate^[The learning rate is the factor by which we will multiply the gradient when adding the negative gradient to each parameter so as to update it for the next learning iteration.].\n- Pull out a minibatch of inputs and target values from the test data set.\n- Calculate the loss on this batch by passing the outputs from the model through the loss function\n- Execute the `.backward()` method to calculate the gradient for all parameters.\n- The next bits will be executed with torch.no_grad(), because we don't want the math inherent to calibrating the parameters themselves to have its gradient captured.\n- Having the gradient stored in the tensor object of each parameter, update each parameter by subtracting the gadient multiplied by the learning rate.\n- Reset the gradient to zero for the next learning iteration.\n\n::: {.cell execution_count=21}\n``` {.python .cell-code code-fold=\"show\" code-line-numbers=\"true\"}\nlr = 0.01\nxb, yb = next(testLoader)\nloss = my_loss(myModel(xb), yb)\nloss.backward()\nwith torch.no_grad():\n    for p in w1, b1, w2, b2:\n        p.data = p.data-p.grad.data*lr\n        p.grad.zero_()\nprint(\"Loss before training: \"+str(loss.item()) +\n      \"  |   Loss after training: \"+str(my_loss(myModel(xb), yb).item()))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLoss before training: 2.3273937702178955  |   Loss after training: 2.3215909004211426\n```\n:::\n:::\n\n\nSuccess! Our measure of loss has reduced after re running the same batch with the adjusted N parameters. Across a large enough dataset^[The changes to parameters can be so small that the actual outcome on any single run doesn't change across a few inputs. But with enough learning iterations we will see the desired outcome.], we would expect to see a reduced error rate associated with this.\n\nLet's try it again, this time printing out the average values of the parameters in the weights and bias vectors, to get a sense for how much they change from one iteration to the next.\n\n::: {.cell execution_count=22}\n``` {.python .cell-code}\nif type(w1.grad) == NoneType:\n    print(tensor([(x.data.mean()) for x in [w1, b1, w2, b2]]))\nelse:\n    print(\"Average parameters: \", tensor(\n        [(x.data.mean(), x.grad.data.mean()) for x in [w1, b1, w2, b2]]))\n    for p in w1, b1, w2, b2:\n        p.grad.zero_()\n\n# Run the learning (copied from last cell):\nlr = 0.01\nxb, yb = next(testLoader)\nloss = my_loss(myModel(xb), yb)\nloss.backward()\nwith torch.no_grad():\n    for p in w1, b1, w2, b2:\n        p.data = p.data-p.grad.data*lr\n        p.grad.zero_()\nprint(\"Loss before training: \"+str(loss.item()) +\n      \"  |   Loss after training: \"+str(my_loss(myModel(xb), yb).item()))\n\n# Print average param values again:\nif type(w1.grad) == NoneType:\n    print(tensor([(x.data.mean()) for x in [w1, b1, w2, b2]]))\nelse:\n    print(\"Average parameters: \", tensor(\n        [(x.data.mean(), x.grad.data.mean()) for x in [w1, b1, w2, b2]]))\n    for p in w1, b1, w2, b2:\n        p.grad.zero_()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAverage parameters:  tensor([[-0.0033,  0.0000],\n        [ 0.0862,  0.0000],\n        [ 0.0337,  0.0000],\n        [-0.0926,  0.0000]])\nLoss before training: 2.353576898574829  |   Loss after training: 2.333199977874756\nAverage parameters:  tensor([[-0.0045,  0.0000],\n        [ 0.0860,  0.0000],\n        [ 0.0337,  0.0000],\n        [-0.0926,  0.0000]])\n```\n:::\n:::\n\n\nWhat we see here is that our change in paramters created a reduction in the measure of loss, *even though* it wasn't even identifiable at 4 decimal points accuracy!\n\nSo let's take it to the next level. We trained on one minibatch of data. Let's try doing a whole epoch- iterating over every minibatch in the training set.\n\nFirst, we'll reset our weights to random numbers, clearing the slate of that last learning:\n\n::: {.cell execution_count=23}\n``` {.python .cell-code code-line-numbers=\"true\"}\nw1 = init_params((8*8, 1))\nb1 = init_params(1)\nw2 = init_params((1, 10))\nb2 = init_params(1)\n\n# Print average param values again:\nif type(w1.grad) == NoneType:\n    print(tensor([(x.data.mean()) for x in [w1, b1, w2, b2]]))\nelse:\n    print(\"Average parameters: \", tensor(\n        [(x.data.mean(), x.grad.data.mean()) for x in [w1, b1, w2, b2]]))\n    for p in w1, b1, w2, b2:\n        p.grad.zero_()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntensor([-0.0039, -0.1600,  0.0096, -0.0360])\n```\n:::\n:::\n\n\nAnd now execute learning.\n\n::: {.cell execution_count=24}\n``` {.python .cell-code code-fold=\"show\" code-line-numbers=\"true\"}\nlr = 0.01\nfor xb, yb in dls[0]:\n    loss = my_loss(myModel(xb), yb)\n    loss.backward()\n    with torch.no_grad():\n        for p in w1, b1, w2, b2:\n            p.data = p.data-p.grad.data*lr\n            p.grad.zero_()\n    print(\"Loss: \"+str(loss.item()))  # Prints loss for each minibatch\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLoss: 2.396993637084961\nLoss: 2.3822765350341797\nLoss: 2.260348320007324\nLoss: 2.3272624015808105\nLoss: 2.2339725494384766\nLoss: 2.2115659713745117\nLoss: 2.36749267578125\nLoss: 2.2987968921661377\nLoss: 2.24696683883667\nLoss: 2.2218852043151855\nLoss: 2.1901235580444336\nLoss: 2.223564386367798\nLoss: 2.222050666809082\nLoss: 2.3343074321746826\nLoss: 2.1647329330444336\nLoss: 2.2685706615448\nLoss: 2.2301828861236572\nLoss: 2.2987945079803467\nLoss: 2.2233567237854004\nLoss: 2.280475378036499\nLoss: 2.2588987350463867\nLoss: 2.242337703704834\nLoss: 2.225619077682495\nLoss: 2.25649356842041\nLoss: 2.2208750247955322\nLoss: 2.2136268615722656\nLoss: 2.2424728870391846\nLoss: 2.233030319213867\nLoss: 2.2520716190338135\nLoss: 2.2793757915496826\nLoss: 2.1994197368621826\nLoss: 2.120187282562256\nLoss: 2.1292951107025146\nLoss: 2.207841396331787\nLoss: 2.205940008163452\nLoss: 2.16477108001709\nLoss: 2.2061352729797363\nLoss: 2.194096565246582\nLoss: 2.1103997230529785\nLoss: 2.218090295791626\nLoss: 2.2401371002197266\nLoss: 2.1660947799682617\nLoss: 2.136357307434082\nLoss: 2.2326133251190186\nLoss: 2.159325361251831\nLoss: 2.1380481719970703\nLoss: 2.1099190711975098\nLoss: 2.1427855491638184\nLoss: 2.1616415977478027\nLoss: 2.1398086547851562\nLoss: 2.19006085395813\nLoss: 2.1740212440490723\nLoss: 1.9568562507629395\nLoss: 2.133082866668701\nLoss: 2.188779592514038\nLoss: 2.2035515308380127\nLoss: 2.0909535884857178\nLoss: 2.1889305114746094\nLoss: 2.1808621883392334\nLoss: 2.2083559036254883\nLoss: 2.2190909385681152\nLoss: 2.0841939449310303\n```\n:::\n:::\n\n\nHmmm.... sometimes when I run this I see the loss stay around the same value, other times it drops just a little before stabilizing... \n\nWe are going to need a better way to look at the trending of the loss function across iterations, so we may as well make that function now:\n\n::: {.cell execution_count=25}\n``` {.python .cell-code code-fold=\"show\" code-line-numbers=\"true\"}\ndef calc_grad(xb, yb, model, f_loss):\n    preds = model(xb)\n    loss = f_loss(preds, yb)\n    loss.backward()\n    return loss.data.item()  # Return the loss (see why later)\n\n\ncalc_grad(mini_x, mini_y, myModel, my_loss)\n```\n\n::: {.cell-output .cell-output-display execution_count=51}\n```\n2.3025851249694824\n```\n:::\n:::\n\n\nThis is another step towards modularizing (if that is a word) our code. Making use of that last function, our training loop now looks like this:\n\n::: {.cell execution_count=26}\n``` {.python .cell-code code-fold=\"show\" code-line-numbers=\"true\"}\n# Initializing weights again for a fresh start\nw1 = init_params((8*8, 1))\nb1 = init_params(1)\nw2 = init_params((1, 10))\nb2 = init_params(1)\n\nprint(\"PreTrain Accuracy: \"+str(validate_epoch(myModel)))\n\n\ndef train_epoch(model, lr, params, f_loss):\n    for xb, yb in dls[0]:\n        calc_grad(xb, yb, model, f_loss)\n        with torch.no_grad():\n            for p in w1, b1, w2, b2:\n                p.data = p.data-p.grad.data*lr\n                p.grad.zero_()\n\n\ntrain_epoch(myModel, 0.01, [w1, b1, w2, b2], my_loss)\nprint(\"PostTrain Accuracy: \"+str(validate_epoch(myModel)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nPreTrain Accuracy: 0.07\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nPostTrain Accuracy: 0.095\n```\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}